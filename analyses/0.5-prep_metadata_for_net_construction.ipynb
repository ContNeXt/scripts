{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare metadata for the R scripts to build the co-expression networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rfigueiredo'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getpass.getuser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.9.1 (v3.9.1:1e5d33e9b9, Dec  7 2020, 12:10:52) \\n[Clang 6.0 (clang-600.0.57)]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sat Jan  8 00:10:47 2022'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.asctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace here the location of the external data dir\n",
    "data_dir = os.path.join(os.path.expanduser(\"~\"), \"contnext_data\", \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tissues = pd.read_table(os.path.join(data_dir, \"misc_data\", \"FULL_tissue_overview.tsv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tissues_afterDL = pd.read_table(os.path.join(data_dir, \"misc_data\", \"FULL_tissue_overview_after_download.tsv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "celltypes = pd.read_table(os.path.join(data_dir, \"misc_data\", \"FULL_celltype_overview.tsv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "celltypes_afterDL = pd.read_table(os.path.join(data_dir, \"misc_data\", \"FULL_celltype_overview_after_download.tsv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "celllines = pd.read_table(os.path.join(data_dir, \"misc_data\", \"FULL_cellline_overview.tsv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "celllines_afterDL = pd.read_table(os.path.join(data_dir, \"misc_data\", \"FULL_cellline_overview_after_download.tsv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UBERON_id</th>\n",
       "      <th>tissue_name</th>\n",
       "      <th>number_experiments</th>\n",
       "      <th>number_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UBERON:0000178</td>\n",
       "      <td>blood</td>\n",
       "      <td>106</td>\n",
       "      <td>3152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UBERON:0002113</td>\n",
       "      <td>kidney</td>\n",
       "      <td>21</td>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UBERON:0002371</td>\n",
       "      <td>bone marrow</td>\n",
       "      <td>21</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UBERON:0001379</td>\n",
       "      <td>vastus lateralis</td>\n",
       "      <td>15</td>\n",
       "      <td>586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UBERON:0002097</td>\n",
       "      <td>skin of body</td>\n",
       "      <td>22</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>UBERON:0004087</td>\n",
       "      <td>vena cava</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>UBERON:0002245</td>\n",
       "      <td>cerebellar hemisphere</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>UBERON:0001875</td>\n",
       "      <td>globus pallidus</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>UBERON:0000995</td>\n",
       "      <td>uterus</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>UBERON:0002407</td>\n",
       "      <td>pericardium</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          UBERON_id            tissue_name  number_experiments  number_samples\n",
       "0    UBERON:0000178                  blood                 106            3152\n",
       "1    UBERON:0002113                 kidney                  21             847\n",
       "2    UBERON:0002371            bone marrow                  21             787\n",
       "3    UBERON:0001379       vastus lateralis                  15             586\n",
       "4    UBERON:0002097           skin of body                  22             570\n",
       "..              ...                    ...                 ...             ...\n",
       "173  UBERON:0004087              vena cava                   1               1\n",
       "174  UBERON:0002245  cerebellar hemisphere                   1               1\n",
       "175  UBERON:0001875        globus pallidus                   1               1\n",
       "176  UBERON:0000995                 uterus                   1               1\n",
       "177  UBERON:0002407            pericardium                   1               1\n",
       "\n",
       "[178 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tissues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tissues meeting criteria in top platform: 48, after download(top platform): 46\n"
     ]
    }
   ],
   "source": [
    "tis_terms = tissues[(tissues[\"number_experiments\"] >= 3) & (tissues[\"number_samples\"] >= 20)][\"tissue_name\"]\n",
    "tis_terms_afterDL = tissues_afterDL[(tissues_afterDL[\"number_experiments\"] >= 3) & (tissues_afterDL[\"number_samples\"] >= 20)][\"tissue_name\"]\n",
    "\n",
    "num_tissues = len(tis_terms)\n",
    "num_tissues_afterDL = len(tis_terms_afterDL)\n",
    "\n",
    "print(f\"tissues meeting criteria in top platform: {num_tissues}, after download(top platform): {num_tissues_afterDL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell types meeting criteria in top platform: 30, after download(top platform): 30\n"
     ]
    }
   ],
   "source": [
    "celltype_terms = celltypes[(celltypes[\"number_experiments\"] >= 3) & (celltypes[\"number_samples\"] >= 20)][\"cell_type_name\"]\n",
    "celltype_terms_afterDL = celltypes_afterDL[(celltypes_afterDL[\"number_experiments\"] >= 3) & (celltypes_afterDL[\"number_samples\"] >= 20)][\"cell_type_name\"]\n",
    "\n",
    "num_celltypes = len(celltype_terms)\n",
    "num_celltypes_afterDL = len(celltype_terms_afterDL)\n",
    "\n",
    "print(f\"cell types meeting criteria in top platform: {num_celltypes}, after download(top platform): {num_celltypes_afterDL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell lines meeting criteria in top platform: 23, after download(top platform): 22\n"
     ]
    }
   ],
   "source": [
    "cellline_terms = celllines[(celllines[\"number_experiments\"] >= 3) & (celllines[\"number_samples\"] >= 20)][\"cell_line_name\"]\n",
    "cellline_terms_afterDL = celllines_afterDL[(celllines_afterDL[\"number_experiments\"] >= 3) & (celllines_afterDL[\"number_samples\"] >= 20)][\"cell_line_name\"]\n",
    "\n",
    "num_celllines = len(cellline_terms)\n",
    "num_celllines_afterDL = len(cellline_terms_afterDL)\n",
    "\n",
    "print(f\"cell lines meeting criteria in top platform: {num_celllines}, after download(top platform): {num_celllines_afterDL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_table(os.path.join(data_dir, \"metadata\", \"final_metadata.tsv\"), index_col=0)\n",
    "metadata.index.name= \"sample_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_afterDL = pd.read_table(os.path.join(data_dir, \"metadata\", \"metadataFinal_afterDataLoading.tsv\"), index_col=0)\n",
    "metadata_afterDL.index.name= \"sample_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#human_data = metadata[metadata['platform'].str.contains(\"GPL570\")]\n",
    "#human_data = human_data.loc[human_data[\"species\"] == \"human\"]\n",
    "\n",
    "human_data_after_DL = metadata_afterDL[metadata_afterDL['platform'].str.contains(\"GPL570\")]\n",
    "human_data_after_DL = human_data_after_DL.loc[human_data_after_DL[\"species\"] == \"human\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_metadata_for_nets(samples_per_id, exp_per_id, metaData, term_type, name_mappings):\n",
    "\n",
    "    path = os.path.join(data_dir, \"data_for_coexp_network_construction\", term_type)\n",
    "\n",
    "    group_name_list = []\n",
    "    group_id_list = []\n",
    "    total_sample_num = 0\n",
    "    total_dataset_num = 0\n",
    "    datasets_total = set()\n",
    "    for ID, num in samples_per_id.items():\n",
    "        if num < 20 : continue # threshold\n",
    "        if exp_per_id[ID] < 3 : continue # threshold\n",
    "\n",
    "        os.makedirs(os.path.join(path,ID), exist_ok=True)\n",
    "\n",
    "        #save group-specific metadata\n",
    "        metaD = metaData.loc[metaData[term_type+\".URL\"].str.contains(ID)]\n",
    "        metaD.to_csv(os.path.join(path, ID, \"metadata.tsv\"), sep=\"\\t\", index=True)\n",
    "\n",
    "        #save list of datasets that contain specific group\n",
    "        datasets = list(metaD[\"dataset\"].unique())\n",
    "\n",
    "        with open(os.path.join(path,ID,\"datasets.txt\"), \"w\") as f:\n",
    "            f.write(\"\\n\".join(datasets))\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "        total_sample_num += num\n",
    "        for ds in datasets:\n",
    "            if ds not in datasets_total:\n",
    "                total_dataset_num += 1\n",
    "                datasets_total.add(ds)\n",
    "\n",
    "        group_name_list.append(name_mappings[ID])\n",
    "        group_id_list.append(ID)\n",
    "    print(f\"{total_sample_num} {term_type} samples from {total_dataset_num} datasets with {len(group_name_list)} groups\")\n",
    "    return group_name_list, group_id_list, datasets_total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tissue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, \"mappings\", \"uberon_name_mappings.json\"), 'r') as f:\n",
    "    uberon_name_mappings = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#human_tissue_subset = human_data[human_data[\"organism part\"].notnull()]\n",
    "#human_tissue_subset = human_tissue_subset[human_tissue_subset[\"organism part\"] != \"\"]\n",
    "#human_tissue_subset = human_tissue_subset[human_tissue_subset['organism part URL'].str.contains(\"UBERON\")]\n",
    "\n",
    "\n",
    "human_tissue_subset_afterDL = human_data_after_DL[human_data_after_DL[\"organism.part\"].notnull()]\n",
    "human_tissue_subset_afterDL = human_tissue_subset_afterDL[human_tissue_subset_afterDL[\"organism.part\"] != \"\"]\n",
    "human_tissue_subset_afterDL = human_tissue_subset_afterDL[human_tissue_subset_afterDL['organism.part.URL'].str.contains(\"UBERON\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dict to keep track of number of samples per uberon_id\n",
    "\n",
    "#samples_per_uberon = {(k.split(\"_\")[-1]).strip() : v for k,v in dict(human_tissue_subset[\"organism part URL\"].value_counts()).items()}\n",
    "samples_per_uberon_afterDL = {(k.split(\"_\")[-1]).strip() : v for k,v in dict(human_tissue_subset_afterDL[\"organism.part.URL\"].value_counts()).items()}\n",
    "\n",
    "# make a dict to keep track of number of datasets/experiments per uberon_id\n",
    "\n",
    "#exp_per_uberon = {(k.split(\"_\")[-1]).strip() : v for k,v in dict(human_tissue_subset.groupby('organism part URL').apply(lambda x: len(x['dataset'].unique()))).items()}\n",
    "exp_per_uberon_afterDL = {(k.split(\"_\")[-1]).strip() : v for k,v in dict(human_tissue_subset_afterDL.groupby('organism.part.URL').apply(lambda x: len(x['dataset'].unique()))).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10145 organism.part samples from 364 datasets with 46 groups\n"
     ]
    }
   ],
   "source": [
    "tissue_group_list, tissue_id_list, tissue_ds_list = prep_metadata_for_nets(samples_per_uberon_afterDL, exp_per_uberon_afterDL, human_tissue_subset_afterDL, \"organism.part\", uberon_name_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0000178',\n",
       " '0002113',\n",
       " '0002371',\n",
       " '0002097',\n",
       " '0001155',\n",
       " '0001379',\n",
       " '0002048',\n",
       " '0000310',\n",
       " '0004802',\n",
       " '0002107',\n",
       " '0001013',\n",
       " '0000029',\n",
       " '0000955',\n",
       " '0002367',\n",
       " '0001134',\n",
       " '0000992',\n",
       " '0002046',\n",
       " '0001295',\n",
       " '0001225',\n",
       " '0001264',\n",
       " '0012168',\n",
       " '0001296',\n",
       " '0012652',\n",
       " '0002018',\n",
       " '0000945',\n",
       " '0001052',\n",
       " '0003729',\n",
       " '0001836',\n",
       " '0000947',\n",
       " '0002331',\n",
       " '0009835',\n",
       " '0001507',\n",
       " '0004911',\n",
       " '0002037',\n",
       " '0001876',\n",
       " '0000002',\n",
       " '0001235',\n",
       " '0016529',\n",
       " '0001987',\n",
       " '0000317',\n",
       " '0001377',\n",
       " '0001158',\n",
       " '0001891',\n",
       " '0002038',\n",
       " '0002316',\n",
       " '0000173']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tissue_id_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, \"mappings\", \"CL_name_mappings.json\"), 'r') as f:\n",
    "    CL_name_mappings = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#human_celltype_subset = human_data[human_data[\"cell type\"].notnull()]\n",
    "#human_celltype_subset = human_celltype_subset[human_celltype_subset[\"cell type\"] != \"\"]\n",
    "#human_celltype_subset = human_celltype_subset[human_celltype_subset['cell type URL'].str.contains(\"CL_\")]\n",
    "\n",
    "human_celltype_subset_after_DL = human_data_after_DL[human_data_after_DL[\"cell.type\"].notnull()]\n",
    "human_celltype_subset_after_DL = human_celltype_subset_after_DL[human_celltype_subset_after_DL[\"cell.type\"] != \"\"]\n",
    "human_celltype_subset_after_DL = human_celltype_subset_after_DL[human_celltype_subset_after_DL['cell.type.URL'].str.contains(\"CL_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dict to keep track of number of samples per CL_id\n",
    "\n",
    "#samples_per_CL = {(k.split(\"_\")[-1]).strip() : v for k,v in dict(human_celltype_subset[\"cell type URL\"].value_counts()).items()}\n",
    "samples_per_CL_afterDL = {(k.split(\"_\")[-1]).strip() : v for k,v in dict(human_celltype_subset_after_DL[\"cell.type.URL\"].value_counts()).items()}\n",
    "\n",
    "# make a dict to keep track of number of datasets/experiments per CL_id\n",
    "\n",
    "#exp_per_CL = {(k.split(\"_\")[-1]).strip() : v for k,v in dict(human_celltype_subset.groupby('cell type URL').apply(lambda x: len(x['dataset'].unique()))).items()}\n",
    "exp_per_CL_afterDL = {(k.split(\"_\")[-1]).strip() : v for k,v in dict(human_celltype_subset_after_DL.groupby('cell.type.URL').apply(lambda x: len(x['dataset'].unique()))).items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4737 cell.type samples from 222 datasets with 30 groups\n"
     ]
    }
   ],
   "source": [
    "ct_group_list, ct_id_list, ct_ds_list = prep_metadata_for_nets(samples_per_CL_afterDL, exp_per_CL_afterDL, human_celltype_subset_after_DL, \"cell.type\", CL_name_mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cell line "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#human_cellline_subset = human_data[human_data[\"cell line\"].notnull()]\n",
    "#human_cellline_subset = human_cellline_subset[human_cellline_subset[\"cell line\"] != \"\"]\n",
    "#human_cellline_subset = human_cellline_subset[human_cellline_subset['cell line URL'].str.contains(\"CLO_\")]\n",
    "\n",
    "human_cellline_subset_afterDL = human_data_after_DL[human_data_after_DL[\"cell.line\"].notnull()]\n",
    "human_cellline_subset_afterDL = human_cellline_subset_afterDL[human_cellline_subset_afterDL[\"cell.line\"] != \"\"]\n",
    "human_cellline_subset_afterDL = human_cellline_subset_afterDL[human_cellline_subset_afterDL['cell.line.URL'].str.contains(\"CLO_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dict to keep track of number of samples per CLO id\n",
    "\n",
    "#samples_per_CLO = {(k.split(\"_\")[-1]).strip() : v for k,v in dict(human_cellline_subset[\"cell line URL\"].value_counts()).items()}\n",
    "samples_per_CLO_afterDL = {(k.split(\"_\")[-1]).strip() : v for k,v in dict(human_cellline_subset_afterDL[\"cell.line.URL\"].value_counts()).items()}\n",
    "\n",
    "# make a dict to keep track of number of datasets/experiments per CLO_id\n",
    "\n",
    "#exp_per_CLO = {(k.split(\"_\")[-1]).strip() : v for k,v in dict(human_cellline_subset.groupby('cell line URL').apply(lambda x: len(x['dataset'].unique()))).items()}\n",
    "exp_per_CLO__afterDL = {(k.split(\"_\")[-1]).strip() : v for k,v in dict(human_cellline_subset_afterDL.groupby('cell.line.URL').apply(lambda x: len(x['dataset'].unique()))).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLO_name_mappings = {}\n",
    "for i, row in human_cellline_subset_afterDL.iterrows():\n",
    "    clo_id = row[\"cell.line.URL\"].split(\"_\")[-1]\n",
    "    if clo_id not in CLO_name_mappings:\n",
    "        CLO_name_mappings[clo_id] = row[\"cell.line\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115 cell.line samples from 103 datasets with 22 groups\n"
     ]
    }
   ],
   "source": [
    "cl_group_list, cl_id_list, cl_ds_list = prep_metadata_for_nets(samples_per_CLO_afterDL, exp_per_CLO__afterDL, human_cellline_subset_afterDL, \"cell.line\", CLO_name_mappings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
